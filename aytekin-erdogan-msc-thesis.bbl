\begin{thebibliography}{10}

\bibitem{toet1989merging}
A.~Toet, L.~J. Van~Ruyven, and J.~M. Valeton, ``Merging thermal and visual
  images by a contrast pyramid,'' {\em Optical engineering}, vol.~28, no.~7,
  pp.~789--792, 1989.

\bibitem{liu2017infrared}
C.~Liu, Y.~Qi, and W.~Ding, ``Infrared and visible image fusion method based on
  saliency detection in sparse domain,'' {\em Infrared Physics \& Technology},
  vol.~83, pp.~94--102, 2017.

\bibitem{bin2016efficient}
Y.~Bin, Y.~Chao, and H.~Guoyu, ``Efficient image fusion with approximate sparse
  representation,'' {\em International Journal of Wavelets, Multiresolution and
  Information Processing}, vol.~14, no.~04, p.~1650024, 2016.

\bibitem{zhang2013dictionary}
Q.~Zhang, Y.~Fu, H.~Li, and J.~Zou, ``Dictionary learning method for joint
  sparse representation-based image fusion,'' {\em Optical Engineering},
  vol.~52, no.~5, pp.~057006--057006, 2013.

\bibitem{hu2017adaptive}
H.-M. Hu, J.~Wu, B.~Li, Q.~Guo, and J.~Zheng, ``An adaptive fusion algorithm
  for visible and infrared videos based on entropy and the cumulative
  distribution of gray levels,'' {\em IEEE Transactions on Multimedia},
  vol.~19, no.~12, pp.~2706--2719, 2017.

\bibitem{he2017infrared}
K.~He, D.~Zhou, X.~Zhang, R.~Nie, Q.~Wang, and X.~Jin, ``Infrared and visible
  image fusion based on target extraction in the nonsubsampled contourlet
  transform domain,'' {\em Journal of Applied Remote Sensing}, vol.~11, no.~1,
  pp.~015011--015011, 2017.

\bibitem{liu2018infrared}
Y.~Liu, X.~Chen, J.~Cheng, H.~Peng, and Z.~Wang, ``Infrared and visible image
  fusion with convolutional neural networks,'' {\em International Journal of
  Wavelets, Multiresolution and Information Processing}, vol.~16, no.~03,
  p.~1850018, 2018.

\bibitem{an2020infrared}
W.-B. An and H.-M. Wang, ``Infrared and visible image fusion with supervised
  convolutional neural network,'' {\em Optik}, vol.~219, p.~165120, 2020.

\bibitem{li2019infrared}
H.~Li, X.-j. Wu, and T.~S. Durrani, ``Infrared and visible image fusion with
  resnet and zero-phase component analysis,'' {\em Infrared Physics \&
  Technology}, vol.~102, p.~103039, 2019.

\bibitem{li2021infrared}
G.~Li, Y.~Lin, and X.~Qu, ``An infrared and visible image fusion method based
  on multi-scale transformation and norm optimization,'' {\em Information
  Fusion}, vol.~71, pp.~109--129, 2021.

\bibitem{li2018infrared}
H.~Li, X.-J. Wu, and J.~Kittler, ``Infrared and visible image fusion using a
  deep learning framework,'' in {\em 2018 24th international conference on
  pattern recognition (ICPR)}, pp.~2705--2710, IEEE, 2018.

\bibitem{ren2018infrared}
X.~Ren, F.~Meng, T.~Hu, Z.~Liu, and C.~Wang, ``Infrared-visible image fusion
  based on convolutional neural networks (cnn),'' in {\em Intelligence Science
  and Big Data Engineering: 8th International Conference, IScIDE 2018, Lanzhou,
  China, August 18--19, 2018, Revised Selected Papers 8}, pp.~301--307,
  Springer, 2018.

\bibitem{yang2021vmdm}
Y.~Yang, J.-X. Liu, S.-Y. Huang, H.-Y. Lu, and W.-Y. Wen, ``Vmdm-fusion: a
  saliency feature representation method for infrared and visible image
  fusion,'' {\em Signal, Image and Video Processing}, pp.~1--9, 2021.

\bibitem{li2020unsupervised}
Y.~Li, J.~Wang, Z.~Miao, and J.~Wang, ``Unsupervised densely attention network
  for infrared and visible image fusion,'' {\em Multimedia Tools and
  Applications}, vol.~79, no.~45-46, pp.~34685--34696, 2020.

\bibitem{liu2019infrared}
Y.~Liu, L.~Dong, Y.~Ji, and W.~Xu, ``Infrared and visible image fusion through
  details preservation,'' {\em Sensors}, vol.~19, no.~20, p.~4556, 2019.

\bibitem{hou2020vif}
R.~Hou, D.~Zhou, R.~Nie, D.~Liu, L.~Xiong, Y.~Guo, and C.~Yu, ``Vif-net: an
  unsupervised framework for infrared and visible image fusion,'' {\em IEEE
  Transactions on Computational Imaging}, vol.~6, pp.~640--651, 2020.

\bibitem{xu2022cufd}
H.~Xu, M.~Gong, X.~Tian, J.~Huang, and J.~Ma, ``Cufd: An encoder--decoder
  network for visible and infrared image fusion based on common and unique
  feature decomposition,'' {\em Computer Vision and Image Understanding},
  vol.~218, p.~103407, 2022.

\bibitem{mustafa2020infrared}
H.~T. Mustafa, J.~Yang, H.~Mustafa, and M.~Zareapoor, ``Infrared and visible
  image fusion based on dilated residual attention network,'' {\em Optik},
  vol.~224, p.~165409, 2020.

\bibitem{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun, ``Deep residual learning for image
  recognition,'' in {\em Proceedings of the IEEE conference on computer vision
  and pattern recognition}, pp.~770--778, 2016.

\bibitem{huang2017densely}
G.~Huang, Z.~Liu, L.~Van Der~Maaten, and K.~Q. Weinberger, ``Densely connected
  convolutional networks,'' in {\em Proceedings of the IEEE conference on
  computer vision and pattern recognition}, pp.~4700--4708, 2017.

\bibitem{mnih2014recurrent}
V.~Mnih, N.~Heess, A.~Graves, and K.~Kavukcuoglu, ``Recurrent models of visual
  attention,'' in {\em Advances in neural information processing systems},
  pp.~2204--2212, 2014.

\bibitem{hinton2006dimensionality}
G.~E. Hinton and R.~R. Salakhutdinov, ``Dimensionality reduction by learning an
  invariant mapping,'' {\em arXiv preprint arXiv:0704.2550}, 2006.

\bibitem{zoph2017neural}
B.~Zoph and Q.~V. Le, ``Neural architecture search with reinforcement
  learning,'' in {\em International Conference on Learning Representations},
  2017.

\bibitem{hinton2006reducing}
G.~E. Hinton and R.~R. Salakhutdinov, ``Reducing the dimensionality of data
  with neural networks,'' {\em science}, vol.~313, no.~5786, pp.~504--507,
  2006.

\bibitem{lin2014microsoft}
T.-Y. Lin, M.~Maire, S.~Belongie, J.~Hays, P.~Perona, D.~Ramanan,
  P.~Doll{\'a}r, and C.~L. Zitnick, ``Microsoft coco: Common objects in
  context,'' in {\em Computer Vision--ECCV 2014: 13th European Conference,
  Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pp.~740--755, Springer, 2014.

\bibitem{raza2020pfaf}
A.~Raza, H.~Huo, and T.~Fang, ``Pfaf-net: Pyramid feature network for
  multimodal fusion,'' {\em IEEE Sensors Letters}, vol.~4, no.~12, pp.~1--4,
  2020.

\bibitem{fu2021dual}
Y.~Fu and X.-J. Wu, ``A dual-branch network for infrared and visible image
  fusion,'' in {\em 2020 25th International Conference on Pattern Recognition
  (ICPR)}, pp.~10675--10680, IEEE, 2021.

\bibitem{jian2020sedrfuse}
L.~Jian, X.~Yang, Z.~Liu, G.~Jeon, M.~Gao, and D.~Chisholm, ``Sedrfuse: A
  symmetric encoder--decoder with residual block network for infrared and
  visible image fusion,'' {\em IEEE Transactions on Instrumentation and
  Measurement}, vol.~70, pp.~1--15, 2020.

\bibitem{wang2022res2fusion}
Z.~Wang, Y.~Wu, J.~Wang, J.~Xu, and W.~Shao, ``Res2fusion: Infrared and visible
  image fusion based on dense res2net and double nonlocal attention models,''
  {\em IEEE Transactions on Instrumentation and Measurement}, vol.~71,
  pp.~1--12, 2022.

\bibitem{zhao2021efficient}
Z.~Zhao, S.~Xu, J.~Zhang, C.~Liang, C.~Zhang, and J.~Liu, ``Efficient and
  model-based infrared and visible image fusion via algorithm unrolling,'' {\em
  IEEE Transactions on Circuits and Systems for Video Technology}, vol.~32,
  no.~3, pp.~1186--1196, 2021.

\bibitem{zhao2021self}
F.~Zhao, W.~Zhao, L.~Yao, and Y.~Liu, ``Self-supervised feature adaption for
  infrared and visible image fusion,'' {\em Information Fusion}, vol.~76,
  pp.~189--203, 2021.

\bibitem{liu2021smoa}
J.~Liu, Y.~Wu, Z.~Huang, R.~Liu, and X.~Fan, ``Smoa: Searching a
  modality-oriented architecture for infrared and visible image fusion,'' {\em
  IEEE Signal Processing Letters}, vol.~28, pp.~1818--1822, 2021.

\bibitem{pan2021densenetfuse}
Y.~Pan, D.~Pi, I.~A. Khan, Z.~U. Khan, J.~Chen, and H.~Meng, ``Densenetfuse: A
  study of deep unsupervised densenet to infrared and visual image fusion,''
  {\em Journal of Ambient Intelligence and Humanized Computing}, pp.~1--13,
  2021.

\bibitem{wang2021unfusion}
Z.~Wang, J.~Wang, Y.~Wu, J.~Xu, and X.~Zhang, ``Unfusion: A unified multi-scale
  densely connected network for infrared and visible image fusion,'' {\em IEEE
  Transactions on Circuits and Systems for Video Technology}, vol.~32, no.~6,
  pp.~3360--3374, 2021.

\bibitem{li2022infrared}
Z.~Li, H.~Wu, L.~Cheng, S.~Luo, and M.~Chen, ``Infrared and visible fusion
  imaging via double-layer fusion denoising neural network,'' {\em Digital
  Signal Processing}, vol.~123, p.~103433, 2022.

\bibitem{peng2022mfdetection}
Y.~Peng, G.~Liu, X.~Xu, D.~P. Bavirisetti, X.~Gu, and X.~Zhang, ``Mfdetection:
  A highly generalized object detection network unified with multilevel
  heterogeneous image fusion,'' {\em Optik}, vol.~266, p.~169599, 2022.

\bibitem{goodfellow2014generative}
I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair,
  A.~Courville, and Y.~Bengio, ``Generative adversarial networks,'' in {\em
  Advances in neural information processing systems}, pp.~2672--2680, 2014.

\bibitem{ma2019fusiongan}
J.~Ma, W.~Yu, P.~Liang, C.~Li, and J.~Jiang, ``Fusiongan: A generative
  adversarial network for infrared and visible image fusion,'' {\em Information
  fusion}, vol.~48, pp.~11--26, 2019.

\bibitem{xu2020lbp}
J.~Xu, X.~Shi, S.~Qin, K.~Lu, H.~Wang, and J.~Ma, ``Lbp-began: A generative
  adversarial network architecture for infrared and visible image fusion,''
  {\em Infrared Physics \& Technology}, vol.~104, p.~103144, 2020.

\bibitem{xu2020infrared}
D.~Xu, Y.~Wang, S.~Xu, K.~Zhu, N.~Zhang, and X.~Zhang, ``Infrared and visible
  image fusion with a generative adversarial network and a residual network,''
  {\em Applied Sciences}, vol.~10, no.~2, p.~554, 2020.

\bibitem{fu2021image}
Y.~Fu, X.-J. Wu, and T.~Durrani, ``Image fusion based on generative adversarial
  network consistent with perception,'' {\em Information Fusion}, vol.~72,
  pp.~110--125, 2021.

\bibitem{wang2021new}
J.~Wang, Y.~Li, and Z.~Miao, ``A new infrared and visible image fusion method
  based on generative adversarial networks and attention mechanism,'' in {\em
  2021 The 4th International Conference on Image and Graphics Processing},
  pp.~109--119, 2021.

\bibitem{ma2020ganmcc}
J.~Ma, H.~Zhang, Z.~Shao, P.~Liang, and H.~Xu, ``Ganmcc: A generative
  adversarial network with multiclassification constraints for infrared and
  visible image fusion,'' {\em IEEE Transactions on Instrumentation and
  Measurement}, vol.~70, pp.~1--14, 2020.

\bibitem{liu2021learning}
J.~Liu, X.~Fan, J.~Jiang, R.~Liu, and Z.~Luo, ``Learning a deep multi-scale
  feature ensemble and an edge-attention guidance for image fusion,'' {\em IEEE
  Transactions on Circuits and Systems for Video Technology}, vol.~32, no.~1,
  pp.~105--119, 2021.

\bibitem{liao2020fusion}
B.~Liao, Y.~Du, and X.~Yin, ``Fusion of infrared-visible images in ue-iot for
  fault point detection based on gan,'' {\em IEEE Access}, vol.~8,
  pp.~79754--79763, 2020.

\bibitem{xu2019learning}
H.~Xu, P.~Liang, W.~Yu, J.~Jiang, and J.~Ma, ``Learning a generative model for
  fusing infrared and visible images via conditional generative adversarial
  network with dual discriminators.,'' in {\em IJCAI}, pp.~3954--3960, 2019.

\bibitem{ma2020ddcgan}
J.~Ma, H.~Xu, J.~Jiang, X.~Mei, and X.-P. Zhang, ``Ddcgan: A dual-discriminator
  conditional generative adversarial network for multi-resolution image
  fusion,'' {\em IEEE Transactions on Image Processing}, vol.~29,
  pp.~4980--4995, 2020.

\bibitem{li2020infrared}
J.~Li, H.~Huo, K.~Liu, and C.~Li, ``Infrared and visible image fusion using
  dual discriminators generative adversarial networks with wasserstein
  distance,'' {\em Information Sciences}, vol.~529, pp.~28--41, 2020.

\bibitem{li2020multigrained}
J.~Li, H.~Huo, C.~Li, R.~Wang, C.~Sui, and Z.~Liu, ``Multigrained attention
  network for infrared and visible image fusion,'' {\em IEEE Transactions on
  Instrumentation and Measurement}, vol.~70, pp.~1--12, 2020.

\bibitem{li2020attentionfgan}
J.~Li, H.~Huo, C.~Li, R.~Wang, and Q.~Feng, ``Attentionfgan: Infrared and
  visible image fusion using attention-based generative adversarial networks,''
  {\em IEEE Transactions on Multimedia}, vol.~23, pp.~1383--1396, 2020.

\bibitem{zhang2021gan}
H.~Zhang, J.~Yuan, X.~Tian, and J.~Ma, ``Gan-fm: Infrared and visible image
  fusion using gan with full-scale skip connection and dual markovian
  discriminators,'' {\em IEEE Transactions on Computational Imaging}, vol.~7,
  pp.~1134--1147, 2021.

\bibitem{song2022triple}
A.~Song, H.~Duan, H.~Pei, and L.~Ding, ``Triple-discriminator generative
  adversarial network for infrared and visible image fusion,'' {\em
  Neurocomputing}, vol.~483, pp.~183--194, 2022.

\bibitem{dosovitskiy2020image}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, {\em et~al.},
  ``An image is worth 16x16 words: Transformers for image recognition at
  scale,'' {\em arXiv preprint arXiv:2010.11929}, 2020.

\bibitem{liu2021swin}
Z.~Liu, Y.~Lin, Y.~Cao, H.~Hu, Y.~Wei, Z.~Zhang, S.~Lin, and B.~Guo, ``Swin
  transformer: Hierarchical vision transformer using shifted windows,'' in {\em
  Proceedings of the IEEE/CVF international conference on computer vision},
  pp.~10012--10022, 2021.

\bibitem{liu2022mfst}
X.~Liu, H.~Gao, Q.~Miao, Y.~Xi, Y.~Ai, and D.~Gao, ``Mfst: Multi-modal feature
  self-adaptive transformer for infrared and visible image fusion,'' {\em
  Remote Sensing}, vol.~14, no.~13, p.~3233, 2022.

\bibitem{zhao2021dndt}
H.~Zhao and R.~Nie, ``Dndt: Infrared and visible image fusion via densenet and
  dual-transformer,'' in {\em 2021 International Conference on Information
  Technology and Biomedical Engineering (ICITBE)}, pp.~71--75, IEEE, 2021.

\bibitem{rao2023tgfuse}
D.~Rao, T.~Xu, and X.-J. Wu, ``Tgfuse: An infrared and visible image fusion
  approach based on transformer and generative adversarial network,'' {\em IEEE
  Transactions on Image Processing}, 2023.

\bibitem{li2022cgtf}
J.~Li, J.~Zhu, C.~Li, X.~Chen, and B.~Yang, ``Cgtf: Convolution-guided
  transformer for infrared and visible image fusion,'' {\em IEEE Transactions
  on Instrumentation and Measurement}, vol.~71, pp.~1--14, 2022.

\bibitem{tang2022ydtr}
W.~Tang, F.~He, and Y.~Liu, ``Ydtr: infrared and visible image fusion via
  y-shape dynamic transformer,'' {\em IEEE Transactions on Multimedia}, 2022.

\bibitem{wang2022swinfuse}
Z.~Wang, Y.~Chen, W.~Shao, H.~Li, and L.~Zhang, ``Swinfuse: A residual swin
  transformer fusion network for infrared and visible images,'' {\em IEEE
  Transactions on Instrumentation and Measurement}, vol.~71, pp.~1--12, 2022.

\bibitem{yang2023dglt}
X.~Yang, H.~Huo, R.~Wang, C.~Li, X.~Liu, and J.~Li, ``Dglt-fusion: A decoupled
  global--local infrared and visible image fusion transformer,'' {\em Infrared
  Physics \& Technology}, vol.~128, p.~104522, 2023.

\bibitem{tang2023tccfusion}
W.~Tang, F.~He, and Y.~Liu, ``Tccfusion: An infrared and visible image fusion
  method based on transformer and cross correlation,'' {\em Pattern
  Recognition}, p.~109295, 2023.

\bibitem{vs2022image}
V.~Vs, J.~M.~J. Valanarasu, P.~Oza, and V.~M. Patel, ``Image fusion
  transformer,'' in {\em 2022 IEEE International Conference on Image Processing
  (ICIP)}, pp.~3566--3570, IEEE, 2022.

\bibitem{fu2021ppt}
Y.~Fu, T.~Xu, X.~Wu, and J.~Kittler, ``Ppt fusion: Pyramid patch transformerfor
  a case study in image fusion,'' {\em arXiv preprint arXiv:2107.13967}, 2021.

\bibitem{ma2022swinfusion}
J.~Ma, L.~Tang, F.~Fan, J.~Huang, X.~Mei, and Y.~Ma, ``Swinfusion: Cross-domain
  long-range learning for general image fusion via swin transformer,'' {\em
  IEEE/CAA Journal of Automatica Sinica}, vol.~9, no.~7, pp.~1200--1217, 2022.

\bibitem{qu2022transfuse}
L.~Qu, S.~Liu, M.~Wang, S.~Li, S.~Yin, Q.~Qiao, and Z.~Song, ``Transfuse: A
  unified transformer-based image fusion framework using self-supervised
  learning,'' {\em arXiv preprint arXiv:2201.07451}, 2022.

\end{thebibliography}
