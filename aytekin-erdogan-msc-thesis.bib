@article{toet1989merging,
  title={Merging thermal and visual images by a contrast pyramid},
  author={Toet, Alexander and Van Ruyven, Lodewik J and Valeton, J Mathee},
  journal={Optical engineering},
  volume={28},
  number={7},
  pages={789--792},
  year={1989},
  publisher={SPIE}
}

@article{bin2016efficient,
  title={Efficient image fusion with approximate sparse representation},
  author={Bin, Yang and Chao, Yang and Guoyu, Huang},
  journal={International Journal of Wavelets, Multiresolution and Information Processing},
  volume={14},
  number={04},
  pages={1650024},
  year={2016},
  publisher={World Scientific}
}

@article{zhang2013dictionary,
  title={Dictionary learning method for joint sparse representation-based image fusion},
  author={Zhang, Qiheng and Fu, Yuli and Li, Haifeng and Zou, Jian},
  journal={Optical Engineering},
  volume={52},
  number={5},
  pages={057006--057006},
  year={2013},
  publisher={Society of Photo-Optical Instrumentation Engineers}
}

@article{hu2017adaptive,
  title={An adaptive fusion algorithm for visible and infrared videos based on entropy and the cumulative distribution of gray levels},
  author={Hu, Hai-Miao and Wu, Jiawei and Li, Bo and Guo, Qiang and Zheng, Jin},
  journal={IEEE Transactions on Multimedia},
  volume={19},
  number={12},
  pages={2706--2719},
  year={2017},
  publisher={IEEE}
}

@article{he2017infrared,
  title={Infrared and visible image fusion based on target extraction in the nonsubsampled contourlet transform domain},
  author={He, Kangjian and Zhou, Dongming and Zhang, Xuejie and Nie, Rencan and Wang, Quan and Jin, Xin},
  journal={Journal of Applied Remote Sensing},
  volume={11},
  number={1},
  pages={015011--015011},
  year={2017},
  publisher={Society of Photo-Optical Instrumentation Engineers}
}

@article{liu2012robust,
  title={Robust recovery of subspace structures by low-rank representation},
  author={Liu, Guangcan and Lin, Zhouchen and Yan, Shuicheng and Sun, Ju and Yu, Yong and Ma, Yi},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={35},
  number={1},
  pages={171--184},
  year={2012},
  publisher={IEEE}
}

@article{liu2017infrared,
  title={Infrared and visible image fusion method based on saliency detection in sparse domain},
  author={Liu, CH and Qi, Y and Ding, WR},
  journal={Infrared Physics \& Technology},
  volume={83},
  pages={94--102},
  year={2017},
  publisher={Elsevier}
}

@article{liu2018infrared,
  title={Infrared and visible image fusion with convolutional neural networks},
  author={Liu, Yu and Chen, Xun and Cheng, Juan and Peng, Hu and Wang, Zengfu},
  journal={International Journal of Wavelets, Multiresolution and Information Processing},
  volume={16},
  number={03},
  pages={1850018},
  year={2018},
  publisher={World Scientific}
}

@article{an2020infrared,
  title={Infrared and visible image fusion with supervised convolutional neural network},
  author={An, Wen-Bo and Wang, Hong-Mei},
  journal={Optik},
  volume={219},
  pages={165120},
  year={2020},
  publisher={Elsevier}
}

@article{li2021infrared,
  title={An infrared and visible image fusion method based on multi-scale transformation and norm optimization},
  author={Li, Guofa and Lin, Yongjie and Qu, Xingda},
  journal={Information Fusion},
  volume={71},
  pages={109--129},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{li2018infrared,
  title={Infrared and visible image fusion using a deep learning framework},
  author={Li, Hui and Wu, Xiao-Jun and Kittler, Josef},
  booktitle={2018 24th international conference on pattern recognition (ICPR)},
  pages={2705--2710},
  year={2018},
  organization={IEEE}
}

@inproceedings{ren2018infrared,
  title={Infrared-visible image fusion based on convolutional neural networks (CNN)},
  author={Ren, Xianyi and Meng, Fanyang and Hu, Tao and Liu, Zhijun and Wang, Changwei},
  booktitle={Intelligence Science and Big Data Engineering: 8th International Conference, IScIDE 2018, Lanzhou, China, August 18--19, 2018, Revised Selected Papers 8},
  pages={301--307},
  year={2018},
  organization={Springer}
}

@article{yang2021vmdm,
  title={VMDM-fusion: a saliency feature representation method for infrared and visible image fusion},
  author={Yang, Yong and Liu, Jia-Xiang and Huang, Shu-Ying and Lu, Hang-Yuan and Wen, Wen-Ying},
  journal={Signal, Image and Video Processing},
  pages={1--9},
  year={2021},
  publisher={Springer}
}

@article{li2020unsupervised,
  title={Unsupervised densely attention network for infrared and visible image fusion},
  author={Li, Yang and Wang, Jixiao and Miao, Zhuang and Wang, Jiabao},
  journal={Multimedia Tools and Applications},
  volume={79},
  number={45-46},
  pages={34685--34696},
  year={2020},
  publisher={Springer}
}

@article{li2019infrared,
  title={Infrared and visible image fusion with ResNet and zero-phase component analysis},
  author={Li, Hui and Wu, Xiao-jun and Durrani, Tariq S},
  journal={Infrared Physics \& Technology},
  volume={102},
  pages={103039},
  year={2019},
  publisher={Elsevier}
}

@article{liu2019infrared,
  title={Infrared and visible image fusion through details preservation},
  author={Liu, Yaochen and Dong, Lili and Ji, Yuanyuan and Xu, Wenhai},
  journal={Sensors},
  volume={19},
  number={20},
  pages={4556},
  year={2019},
  publisher={MDPI}
}

@article{hou2020vif,
  title={VIF-Net: an unsupervised framework for infrared and visible image fusion},
  author={Hou, Ruichao and Zhou, Dongming and Nie, Rencan and Liu, Dong and Xiong, Lei and Guo, Yanbu and Yu, Chuanbo},
  journal={IEEE Transactions on Computational Imaging},
  volume={6},
  pages={640--651},
  year={2020},
  publisher={IEEE}
}

@article{xu2022cufd,
  title={CUFD: An encoder--decoder network for visible and infrared image fusion based on common and unique feature decomposition},
  author={Xu, Han and Gong, Meiqi and Tian, Xin and Huang, Jun and Ma, Jiayi},
  journal={Computer Vision and Image Understanding},
  volume={218},
  pages={103407},
  year={2022},
  publisher={Elsevier}
}

@article{mustafa2020infrared,
  title={Infrared and visible image fusion based on dilated residual attention network},
  author={Mustafa, Hafiz Tayyab and Yang, Jie and Mustafa, Hamza and Zareapoor, Masoumeh},
  journal={Optik},
  volume={224},
  pages={165409},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@inproceedings{mnih2014recurrent,
  title={Recurrent models of visual attention},
  author={Mnih, Volodymyr and Heess, Nicolas and Graves, Alex and Kavukcuoglu, Koray},
  booktitle={Advances in neural information processing systems},
  pages={2204--2212},
  year={2014}
}

@article{hinton2006dimensionality,
  title={Dimensionality reduction by learning an invariant mapping},
  author={Hinton, Geoffrey E and Salakhutdinov, Ruslan R},
  journal={arXiv preprint arXiv:0704.2550},
  year={2006}
}

@inproceedings{zoph2017neural,
  title={Neural Architecture Search with Reinforcement Learning},
  author={Zoph, Barret and Le, Quoc V},
  booktitle={International Conference on Learning Representations},
  year={2017}
}

@article{hinton2006reducing,
  title={Reducing the dimensionality of data with neural networks},
  author={Hinton, Geoffrey E and Salakhutdinov, Ruslan R},
  journal={science},
  volume={313},
  number={5786},
  pages={504--507},
  year={2006},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@article{raza2020pfaf,
  title={PFAF-Net: Pyramid feature network for multimodal fusion},
  author={Raza, Asif and Huo, Hong and Fang, Tao},
  journal={IEEE Sensors Letters},
  volume={4},
  number={12},
  pages={1--4},
  year={2020},
  publisher={IEEE}
}

@inproceedings{fu2021dual,
  title={A dual-branch network for infrared and visible image fusion},
  author={Fu, Yu and Wu, Xiao-Jun},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)},
  pages={10675--10680},
  year={2021},
  organization={IEEE}
}

@article{jian2020sedrfuse,
  title={SEDRFuse: A symmetric encoder--decoder with residual block network for infrared and visible image fusion},
  author={Jian, Lihua and Yang, Xiaomin and Liu, Zheng and Jeon, Gwanggil and Gao, Mingliang and Chisholm, David},
  journal={IEEE Transactions on Instrumentation and Measurement},
  volume={70},
  pages={1--15},
  year={2020},
  publisher={IEEE}
}

@article{wang2022res2fusion,
  title={Res2Fusion: Infrared and visible image fusion based on dense Res2net and double nonlocal attention models},
  author={Wang, Zhishe and Wu, Yuanyuan and Wang, Junyao and Xu, Jiawei and Shao, Wenyu},
  journal={IEEE Transactions on Instrumentation and Measurement},
  volume={71},
  pages={1--12},
  year={2022},
  publisher={IEEE}
}

@article{zhao2021efficient,
  title={Efficient and model-based infrared and visible image fusion via algorithm unrolling},
  author={Zhao, Zixiang and Xu, Shuang and Zhang, Jiangshe and Liang, Chengyang and Zhang, Chunxia and Liu, Junmin},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={32},
  number={3},
  pages={1186--1196},
  year={2021},
  publisher={IEEE}
}

@article{zhao2021self,
  title={Self-supervised feature adaption for infrared and visible image fusion},
  author={Zhao, Fan and Zhao, Wenda and Yao, Libo and Liu, Yu},
  journal={Information Fusion},
  volume={76},
  pages={189--203},
  year={2021},
  publisher={Elsevier}
}

@article{liu2021smoa,
  title={SMoA: Searching a modality-oriented architecture for infrared and visible image fusion},
  author={Liu, Jinyuan and Wu, Yuhui and Huang, Zhanbo and Liu, Risheng and Fan, Xin},
  journal={IEEE Signal Processing Letters},
  volume={28},
  pages={1818--1822},
  year={2021},
  publisher={IEEE}
}

@article{pan2021densenetfuse,
  title={DenseNetFuse: A study of deep unsupervised DenseNet to infrared and visual image fusion},
  author={Pan, Yue and Pi, Dechang and Khan, Izhar Ahmed and Khan, Zaheer Ullah and Chen, Junfu and Meng, Han},
  journal={Journal of Ambient Intelligence and Humanized Computing},
  pages={1--13},
  year={2021},
  publisher={Springer}
}

@article{wang2021unfusion,
  title={UNFusion: A unified multi-scale densely connected network for infrared and visible image fusion},
  author={Wang, Zhishe and Wang, Junyao and Wu, Yuanyuan and Xu, Jiawei and Zhang, Xiaoqin},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={32},
  number={6},
  pages={3360--3374},
  year={2021},
  publisher={IEEE}
}

@article{li2022infrared,
  title={Infrared and visible fusion imaging via double-layer fusion denoising neural network},
  author={Li, Zhuo and Wu, Heng and Cheng, Lianglun and Luo, Shaojuan and Chen, Meiyun},
  journal={Digital Signal Processing},
  volume={123},
  pages={103433},
  year={2022},
  publisher={Elsevier}
}

@article{peng2022mfdetection,
  title={MFDetection: A highly generalized object detection network unified with multilevel heterogeneous image fusion},
  author={Peng, Yao and Liu, Gang and Xu, Xiang and Bavirisetti, Durga Prasad and Gu, Xinjie and Zhang, Xiangbo},
  journal={Optik},
  volume={266},
  pages={169599},
  year={2022},
  publisher={Elsevier}
}

@article{ma2019fusiongan,
  title={FusionGAN: A generative adversarial network for infrared and visible image fusion},
  author={Ma, Jiayi and Yu, Wei and Liang, Pengwei and Li, Chang and Jiang, Junjun},
  journal={Information fusion},
  volume={48},
  pages={11--26},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{goodfellow2014generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  booktitle={Advances in neural information processing systems},
  pages={2672--2680},
  year={2014}
}

@article{xu2020lbp,
  title={LBP-BEGAN: A generative adversarial network architecture for infrared and visible image fusion},
  author={Xu, Jiangtao and Shi, Xingping and Qin, Shuzhen and Lu, Kaige and Wang, Han and Ma, Jianguo},
  journal={Infrared Physics \& Technology},
  volume={104},
  pages={103144},
  year={2020},
  publisher={Elsevier}
}

@article{xu2020infrared,
  title={Infrared and visible image fusion with a generative adversarial network and a residual network},
  author={Xu, Dongdong and Wang, Yongcheng and Xu, Shuyan and Zhu, Kaiguang and Zhang, Ning and Zhang, Xin},
  journal={Applied Sciences},
  volume={10},
  number={2},
  pages={554},
  year={2020},
  publisher={MDPI}
}

@article{fu2021image,
  title={Image fusion based on generative adversarial network consistent with perception},
  author={Fu, Yu and Wu, Xiao-Jun and Durrani, Tariq},
  journal={Information Fusion},
  volume={72},
  pages={110--125},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{wang2021new,
  title={A New Infrared and Visible Image Fusion Method Based on Generative Adversarial Networks and Attention Mechanism},
  author={Wang, Jixiao and Li, Yang and Miao, Zhuang},
  booktitle={2021 The 4th International Conference on Image and Graphics Processing},
  pages={109--119},
  year={2021}
}

@article{ma2020ganmcc,
  title={GANMcC: A generative adversarial network with multiclassification constraints for infrared and visible image fusion},
  author={Ma, Jiayi and Zhang, Hao and Shao, Zhenfeng and Liang, Pengwei and Xu, Han},
  journal={IEEE Transactions on Instrumentation and Measurement},
  volume={70},
  pages={1--14},
  year={2020},
  publisher={IEEE}
}

@article{liu2021learning,
  title={Learning a deep multi-scale feature ensemble and an edge-attention guidance for image fusion},
  author={Liu, Jinyuan and Fan, Xin and Jiang, Ji and Liu, Risheng and Luo, Zhongxuan},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={32},
  number={1},
  pages={105--119},
  year={2021},
  publisher={IEEE}
}

@article{liao2020fusion,
  title={Fusion of infrared-visible images in UE-IoT for fault point detection based on GAN},
  author={Liao, Bin and Du, You and Yin, Xiangyun},
  journal={IEEE Access},
  volume={8},
  pages={79754--79763},
  year={2020},
  publisher={IEEE}
}

@inproceedings{xu2019learning,
  title={Learning a Generative Model for Fusing Infrared and Visible Images via Conditional Generative Adversarial Network with Dual Discriminators.},
  author={Xu, Han and Liang, Pengwei and Yu, Wei and Jiang, Junjun and Ma, Jiayi},
  booktitle={IJCAI},
  pages={3954--3960},
  year={2019}
}

@article{ma2020ddcgan,
  title={DDcGAN: A dual-discriminator conditional generative adversarial network for multi-resolution image fusion},
  author={Ma, Jiayi and Xu, Han and Jiang, Junjun and Mei, Xiaoguang and Zhang, Xiao-Ping},
  journal={IEEE Transactions on Image Processing},
  volume={29},
  pages={4980--4995},
  year={2020},
  publisher={IEEE}
}

@article{li2020infrared,
  title={Infrared and visible image fusion using dual discriminators generative adversarial networks with Wasserstein distance},
  author={Li, Jing and Huo, Hongtao and Liu, Kejian and Li, Chang},
  journal={Information Sciences},
  volume={529},
  pages={28--41},
  year={2020},
  publisher={Elsevier}
}

@article{li2020multigrained,
  title={Multigrained attention network for infrared and visible image fusion},
  author={Li, Jing and Huo, Hongtao and Li, Chang and Wang, Renhua and Sui, Chenhong and Liu, Zhao},
  journal={IEEE Transactions on Instrumentation and Measurement},
  volume={70},
  pages={1--12},
  year={2020},
  publisher={IEEE}
}

@article{li2020attentionfgan,
  title={AttentionFGAN: Infrared and visible image fusion using attention-based generative adversarial networks},
  author={Li, Jing and Huo, Hongtao and Li, Chang and Wang, Renhua and Feng, Qi},
  journal={IEEE Transactions on Multimedia},
  volume={23},
  pages={1383--1396},
  year={2020},
  publisher={IEEE}
}

@article{zhang2021gan,
  title={GAN-FM: Infrared and visible image fusion using GAN with full-scale skip connection and dual Markovian discriminators},
  author={Zhang, Hao and Yuan, Jiteng and Tian, Xin and Ma, Jiayi},
  journal={IEEE Transactions on Computational Imaging},
  volume={7},
  pages={1134--1147},
  year={2021},
  publisher={IEEE}
}

@article{song2022triple,
  title={Triple-discriminator generative adversarial network for infrared and visible image fusion},
  author={Song, Anyang and Duan, Huixian and Pei, Haodong and Ding, Lei},
  journal={Neurocomputing},
  volume={483},
  pages={183--194},
  year={2022},
  publisher={Elsevier}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10012--10022},
  year={2021}
}

@inproceedings{lebedev2019multisensor,
  title={Multisensor image fusion based on generative adversarial networks},
  author={Lebedev, MA and Komarov, DV and Vygolov, OV and Vizilter, Yu V},
  booktitle={Image and Signal Processing for Remote Sensing XXV},
  volume={11155},
  pages={565--574},
  year={2019},
  organization={SPIE}
}

@article{li2019coupled,
  title={Coupled GAN with relativistic discriminators for infrared and visible images fusion},
  author={Li, Qilei and Lu, Lu and Li, Zhen and Wu, Wei and Liu, Zheng and Jeon, Gwanggil and Yang, Xiaomin},
  journal={IEEE Sensors Journal},
  volume={21},
  number={6},
  pages={7458--7467},
  year={2019},
  publisher={IEEE}
}

@article{li2013image,
  title={Image fusion with guided filtering},
  author={Li, Shutao and Kang, Xudong and Hu, Jianwen},
  journal={IEEE Transactions on Image processing},
  volume={22},
  number={7},
  pages={2864--2875},
  year={2013},
  publisher={IEEE}
}

//transformers x8
@inproceedings{zhao2021dndt,
  title={Dndt: Infrared and visible image fusion via densenet and dual-transformer},
  author={Zhao, Haibo and Nie, Rencan},
  booktitle={2021 International Conference on Information Technology and Biomedical Engineering (ICITBE)},
  pages={71--75},
  year={2021},
  organization={IEEE}
}

@article{rao2023tgfuse,
  title={Tgfuse: An infrared and visible image fusion approach based on transformer and generative adversarial network},
  author={Rao, Dongyu and Xu, Tianyang and Wu, Xiao-Jun},
  journal={IEEE Transactions on Image Processing},
  year={2023},
  publisher={IEEE}
}

@article{li2022cgtf,
  title={Cgtf: Convolution-guided transformer for infrared and visible image fusion},
  author={Li, Jing and Zhu, Jianming and Li, Chang and Chen, Xun and Yang, Bin},
  journal={IEEE Transactions on Instrumentation and Measurement},
  volume={71},
  pages={1--14},
  year={2022},
  publisher={IEEE}
}

@article{tang2022ydtr,
  title={Ydtr: infrared and visible image fusion via y-shape dynamic transformer},
  author={Tang, Wei and He, Fazhi and Liu, Yu},
  journal={IEEE Transactions on Multimedia},
  year={2022},
  publisher={IEEE}
}

@article{wang2022swinfuse,
  title={SwinFuse: A residual swin transformer fusion network for infrared and visible images},
  author={Wang, Zhishe and Chen, Yanlin and Shao, Wenyu and Li, Hui and Zhang, Lei},
  journal={IEEE Transactions on Instrumentation and Measurement},
  volume={71},
  pages={1--12},
  year={2022},
  publisher={IEEE}
}

@article{liu2022mfst,
  title={MFST: Multi-Modal Feature Self-Adaptive Transformer for Infrared and Visible Image Fusion},
  author={Liu, Xiangzeng and Gao, Haojie and Miao, Qiguang and Xi, Yue and Ai, Yunfeng and Gao, Dingguo},
  journal={Remote Sensing},
  volume={14},
  number={13},
  pages={3233},
  year={2022},
  publisher={MDPI}
}

@article{yang2023dglt,
  title={DGLT-Fusion: A decoupled global--local infrared and visible image fusion transformer},
  author={Yang, Xin and Huo, Hongtao and Wang, Renhua and Li, Chang and Liu, Xiaowen and Li, Jing},
  journal={Infrared Physics \& Technology},
  volume={128},
  pages={104522},
  year={2023},
  publisher={Elsevier}
}

@article{tang2023tccfusion,
  title={TCCFusion: An Infrared and Visible Image Fusion Method based on Transformer and Cross Correlation},
  author={Tang, Wei and He, Fazhi and Liu, Yu},
  journal={Pattern Recognition},
  pages={109295},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{vs2022image,
  title={Image fusion transformer},
  author={Vs, Vibashan and Valanarasu, Jeya Maria Jose and Oza, Poojan and Patel, Vishal M},
  booktitle={2022 IEEE International Conference on Image Processing (ICIP)},
  pages={3566--3570},
  year={2022},
  organization={IEEE}
}

@article{fu2021ppt,
  title={Ppt fusion: Pyramid patch transformerfor a case study in image fusion},
  author={Fu, Yu and Xu, TianYang and Wu, XiaoJun and Kittler, Josef},
  journal={arXiv preprint arXiv:2107.13967},
  year={2021}
}

@article{ma2022swinfusion,
  title={SwinFusion: Cross-domain long-range learning for general image fusion via swin transformer},
  author={Ma, Jiayi and Tang, Linfeng and Fan, Fan and Huang, Jun and Mei, Xiaoguang and Ma, Yong},
  journal={IEEE/CAA Journal of Automatica Sinica},
  volume={9},
  number={7},
  pages={1200--1217},
  year={2022},
  publisher={IEEE}
}

@article{qu2022transfuse,
  title={TransFuse: A unified transformer-based image fusion framework using self-supervised learning},
  author={Qu, Linhao and Liu, Shaolei and Wang, Manning and Li, Shiman and Yin, Siqi and Qiao, Qin and Song, Zhijian},
  journal={arXiv preprint arXiv:2201.07451},
  year={2022}
}

@inproceedings{zhao2021dndt,
  title={Dndt: Infrared and visible image fusion via densenet and dual-transformer},
  author={Zhao, Haibo and Nie, Rencan},
  booktitle={2021 International Conference on Information Technology and Biomedical Engineering (ICITBE)},
  pages={71--75},
  year={2021},
  organization={IEEE}
}

@article{wang2022unsupervised,
  title={Unsupervised misaligned infrared and visible image fusion via cross-modality image generation and registration},
  author={Wang, Di and Liu, Jinyuan and Fan, Xin and Liu, Risheng},
  journal={arXiv preprint arXiv:2205.11876},
  year={2022}
}

@article{xu2021classification,
  title={Classification saliency-based rule for visible and infrared image fusion},
  author={Xu, Han and Zhang, Hao and Ma, Jiayi},
  journal={IEEE Transactions on Computational Imaging},
  volume={7},
  pages={824--836},
  year={2021},
  publisher={IEEE}
}

@article{jian2021infrared,
  title={Infrared and visible image fusion based on deep decomposition network and saliency analysis},
  author={Jian, Lihua and Rayhana, Rakiba and Ma, Ling and Wu, Shaowu and Liu, Zheng and Jiang, Huiqin},
  journal={IEEE Transactions on Multimedia},
  volume={24},
  pages={3314--3326},
  year={2021},
  publisher={IEEE}
}

@article{petro2014multiscale,
  title={Multiscale retinex},
  author={Petro, Ana Bel{\'e}n and Sbert, Catalina and Morel, Jean-Michel},
  journal={Image Processing On Line},
  pages={71--88},
  year={2014}
}

@article{ma2020ganmcc,
  title={GANMcC: A generative adversarial network with multiclassification constraints for infrared and visible image fusion},
  author={Ma, Jiayi and Zhang, Hao and Shao, Zhenfeng and Liang, Pengwei and Xu, Han},
  journal={IEEE Transactions on Instrumentation and Measurement},
  volume={70},
  pages={1--14},
  year={2020},
  publisher={IEEE}
}

@article{zhang2020ifcnn,
  title={IFCNN: A general image fusion framework based on convolutional neural network},
  author={Zhang, Yu and Liu, Yu and Sun, Peng and Yan, Han and Zhao, Xiaolin and Zhang, Li},
  journal={Information Fusion},
  volume={54},
  pages={99--118},
  year={2020},
  publisher={Elsevier}
}

@article{liu2018infrared,
  title={Infrared and visible image fusion with convolutional neural networks},
  author={Liu, Yu and Chen, Xun and Cheng, Juan and Peng, Hu and Wang, Zengfu},
  journal={International Journal of Wavelets, Multiresolution and Information Processing},
  volume={16},
  number={03},
  pages={1850018},
  year={2018},
  publisher={World Scientific}
}

@article{wang2019generative,
  title={A generative image fusion approach based on supervised deep convolution network driven by weighted gradient flow},
  author={Wang, Meng and Liu, Xingwang and Jin, Huaiping},
  journal={Image and Vision Computing},
  volume={86},
  pages={1--16},
  year={2019},
  publisher={Elsevier}
}

@article{feng2020fully,
  title={Fully convolutional network-based infrared and visible image fusion},
  author={Feng, Yufang and Lu, Houqing and Bai, Jingbo and Cao, Lin and Yin, Hong},
  journal={Multimedia Tools and Applications},
  volume={79},
  number={21-22},
  pages={15001--15014},
  year={2020},
  publisher={Springer}
}

@article{luo2021ifsepr,
  title={IFSepR: A general framework for image fusion based on separate representation learning},
  author={Luo, Xiaoqing and Gao, Yuanhao and Wang, Anqi and Zhang, Zhancheng and Wu, Xiao-Jun},
  journal={IEEE Transactions on Multimedia},
  year={2021},
  publisher={IEEE}
}

@article{zhu2022iplf,
  title={IPLF: A novel image pair learning fusion network for infrared and visible image},
  author={Zhu, Depeng and Zhan, Weida and Jiang, Yichun and Xu, Xiaoyu and Guo, Renzhong},
  journal={IEEE Sensors Journal},
  volume={22},
  number={9},
  pages={8808--8817},
  year={2022},
  publisher={IEEE}
}

@article{ma2021stdfusionnet,
  title={STDFusionNet: An infrared and visible image fusion network based on salient target detection},
  author={Ma, Jiayi and Tang, Linfeng and Xu, Meilong and Zhang, Hao and Xiao, Guobao},
  journal={IEEE Transactions on Instrumentation and Measurement},
  volume={70},
  pages={1--13},
  year={2021},
  publisher={IEEE}
}

@article{shopovska2019deep,
  title={Deep visible and thermal image fusion for enhanced pedestrian visibility},
  author={Shopovska, Ivana and Jovanov, Ljubomir and Philips, Wilfried},
  journal={Sensors},
  volume={19},
  number={17},
  pages={3727},
  year={2019},
  publisher={MDPI}
}

@article{tang2022image,
  title={Image fusion in the loop of high-level vision tasks: A semantic-aware real-time infrared and visible image fusion network},
  author={Tang, Linfeng and Yuan, Jiteng and Ma, Jiayi},
  journal={Information Fusion},
  volume={82},
  pages={28--42},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{liu2022target,
  title={Target-aware dual adversarial learning and a multi-scenario multi-modality benchmark to fuse infrared and visible for object detection},
  author={Liu, Jinyuan and Fan, Xin and Huang, Zhanbo and Wu, Guanyao and Liu, Risheng and Zhong, Wei and Luo, Zhongxuan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5802--5811},
  year={2022}
}

@article{luo2021latraivf,
  title={LatRAIVF: An infrared and visible image fusion method based on latent regression and adversarial training},
  author={Luo, Xiaoqing and Wang, Anqi and Zhang, Zhancheng and Xiang, Xinguang and Wu, Xiao-Jun},
  journal={IEEE Transactions on Instrumentation and Measurement},
  volume={70},
  pages={1--16},
  year={2021},
  publisher={IEEE}
}

@inproceedings{patel2020approach,
  title={An approach for fusion of thermal and visible images},
  author={Patel, Heena and Prajapati, Kalpesh and Chudasama, Vishal and Upla, Kishor P},
  booktitle={Emerging Technology Trends in Electronics, Communication and Networking: Third International Conference, ET2ECN 2020, Surat, India, February 7--8, 2020, Revised Selected Papers 3},
  pages={225--234},
  year={2020},
  organization={Springer}
}

@article{zhao2021efficient,
  title={Efficient and model-based infrared and visible image fusion via algorithm unrolling},
  author={Zhao, Zixiang and Xu, Shuang and Zhang, Jiangshe and Liang, Chengyang and Zhang, Chunxia and Liu, Junmin},
  journal={IEEE Transactions on Circuits and Systems for Video Technology},
  volume={32},
  number={3},
  pages={1186--1196},
  year={2021},
  publisher={IEEE}
}

@article{li2019infrared,
  title={Infrared and visible image fusion with ResNet and zero-phase component analysis},
  author={Li, Hui and Wu, Xiao-jun and Durrani, Tariq S},
  journal={Infrared Physics \& Technology},
  volume={102},
  pages={103039},
  year={2019},
  publisher={Elsevier}
}

@article{li2021rfn,
  title={RFN-Nest: An end-to-end residual fusion network for infrared and visible images},
  author={Li, Hui and Wu, Xiao-Jun and Kittler, Josef},
  journal={Information Fusion},
  volume={73},
  pages={72--86},
  year={2021},
  publisher={Elsevier}
}

@article{toet2014tno,
  title={TNO Image Fusion Dataset< https://figshare. com/articles},
  author={Toet, Alexander and others},
  journal={TN\_Image\_Fusion\_Dataset/1008029},
  year={2014}
}

@article{toet2014tno,
  title={TNO Image Fusion Dataset< https://figshare. com/articles},
  author={Toet, Alexander and others},
  journal={TN\_Image\_Fusion\_Dataset/1008029},
  year={2014}
}

@misc{toet2014tno,   
    title = {Website Title},   
    url = {https://figshare.com/articles/dataset/TNO Image Fusion Dataset/1008029},   
    author = {Toet, Alexander and others},   
    year = {2014},   
    note = {Accessed on May 29, 2023} 
}

@misc{inodataset,   
    title = {INO Videos Analytics Dataset},   
    url = {https://www.ino.ca/en/technologies/video-analytics-dataset/videos/},   
    year = {2016},   
    note = {Accessed on May 29, 2023} 
}

@inproceedings{ha2017mfnet,
  title={MFNet: Towards real-time semantic segmentation for autonomous vehicles with multi-spectral scenes},
  author={Ha, Qishen and Watanabe, Kohei and Karasawa, Takumi and Ushiku, Yoshitaka and Harada, Tatsuya},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={5108--5115},
  year={2017},
  organization={IEEE}
}

@inproceedings{xu2020fusiondn,
  title={Fusiondn: A unified densely connected network for image fusion},
  author={Xu, Han and Ma, Jiayi and Le, Zhuliang and Jiang, Junjun and Guo, Xiaojie},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={07},
  pages={12484--12491},
  year={2020}
}

@inproceedings{zhang2020vifb,
  title={VIFB: A visible and infrared image fusion benchmark},
  author={Zhang, Xingchen and Ye, Ping and Xiao, Gang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={104--105},
  year={2020}
}

@inproceedings{jia2021llvip,
  title={LLVIP: A visible-infrared paired dataset for low-light vision},
  author={Jia, Xinyu and Zhu, Chuang and Li, Minzhen and Tang, Wenqi and Zhou, Wenli},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3496--3504},
  year={2021}
}

@article{peibei2021debiased,
  title={Debiased Subjective Assessment of Real-World Image Enhancement},
  author={Peibei, Cao and Zhangyang, Wang and Kede, Ma},
  journal={arXiv preprint arXiv:2106.10080},
  year={2021}
}

@article{bulanon2009image,
  title={Image fusion of visible and thermal images for fruit detection},
  author={Bulanon, DM and Burks, TF and Alchanatis, V},
  journal={Biosystems engineering},
  volume={103},
  number={1},
  pages={12--22},
  year={2009},
  publisher={Elsevier}
}

@article{eskicioglu1995image,
  title={Image quality measures and their performance},
  author={Eskicioglu, Ahmet M and Fisher, Paul S},
  journal={IEEE Transactions on communications},
  volume={43},
  number={12},
  pages={2959--2965},
  year={1995},
  publisher={IEEE}
}

@article{hossny2008comments,
  title={Comments on'Information measure for performance of image fusion'},
  author={Hossny, Mohammed and Nahavandi, Saeid and Creighton, Douglas},
  year={2008},
  publisher={Deakin University}
}

@inproceedings{zhang2020vifb,
  title={VIFB: A visible and infrared image fusion benchmark},
  author={Zhang, Xingchen and Ye, Ping and Xiao, Gang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={104--105},
  year={2020}
}

@article{zhang2021deep,
  title={Deep learning-based multi-focus image fusion: A survey and a comparative study},
  author={Zhang, Xingchen},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={44},
  number={9},
  pages={4819--4838},
  year={2021},
  publisher={IEEE}
}

@article{liu2011objective,
  title={Objective assessment of multiresolution image fusion algorithms for context enhancement in night vision: a comparative study},
  author={Liu, Zheng and Blasch, Erik and Xue, Zhiyun and Zhao, Jiying and Laganiere, Robert and Wu, Wei},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={34},
  number={1},
  pages={94--109},
  year={2011},
  publisher={IEEE}
}


@article{ma2019infrared,
  title={Infrared and visible image fusion methods and applications: A survey},
  author={Ma, Jiayi and Ma, Yong and Li, Chang},
  journal={Information Fusion},
  volume={45},
  pages={153--178},
  year={2019},
  publisher={Elsevier}
}